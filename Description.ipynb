{"cells":[{"cell_type":"markdown","source":["#### 1. Overview"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d4edbc10-78e1-4ab2-ab3e-0123780a5b3b","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["The company `Food in Baggins` (FiB) is a food delivery app expanding its operations across Middle Earth.  \nOne of the greatest challenges for the year of 2021 was to grow its MUB (Monthly Unique Buyers) base, spending in the most efficient way the large amount of money that was injected into the company.  \n  \nIn order to this, FiB marketing team decided to invest in discount vouchers, with the hypothesis that this would incentivize more customers to convert.  \nThe dataset `mkt_test_assignment_sample` contains the data of a marketing AB test performed in june/21, in order to validate this hypothesis. The test simply consisted in sending discount vouchers to all customers in the treatment variant, so we could analyze the results and decide if the discount campaign should be rollouted as a growth lever.  \n\nlink sobre teste AB"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"704c8de0-d307-4669-b16b-3699e6ff685a","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.sql import functions as f\n\norders_sample = spark.read.parquet(f\"s3://dev-ifood-kairos/misc/bda/ord_sample\")\nkairos_sample = spark.read.parquet(f\"s3://dev-ifood-kairos/misc/bda/mkt_test_assignment_sample\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"nuid":"1ffb4126-fc8f-4d62-bfdb-69f310aaa386","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>\n","<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["orders_by_account = (\n    orders_sample\n    .filter(f.col('reference_date')>='2021-06-01')\n    .filter(f.col('reference_date')<'2021-07-01')\n    .groupBy('account_id', 'reference_date')\n    .agg(\n        f.countDistinct('order_id').alias('orders'),\n        f.sum('discount_vouchers_used').alias('vouchers_used'),\n        f.sum('subsidy').alias('subsidy'),\n        f.avg('order_total').alias('aov')\n    )\n)\n\n(\n    kairos_sample\n    .filter(f.col('reference_month')=='2021-06-01')\n    .join(orders_by_account, ['account_id', 'reference_date'], 'left')\n    .groupBy('test_assignment')\n    .agg(\n        f.count('account_id').alias('test_size'),\n        f.round((f.sum( f.when(f.col('orders') > 0, 1).otherwise(0) )), 3).alias('conversions'),\n        f.round((f.sum( f.when(f.col('orders') > 0, 1).otherwise(0) ) / f.count('account_id') ), 3).alias('conversion_rate'),\n        f.round(f.sum('subsidy'), 0).alias('sub_total'),\n        (f.sum( f.when(f.col('vouchers_used') > 0, 1).otherwise(0) ) ).alias('vouchers_used'),\n        f.round(f.avg('aov'),0).alias('aov')\n    )    \n    .display()\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"nuid":"b606e02d-dc80-4b00-9386-18493b8f0475","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["control",147962,10899,0.074,0.0,0,2330.0],["test",164460,12093,0.074,339914.0,882,2298.0]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"metadata":"{}","name":"test_assignment","type":"\"string\""},{"metadata":"{}","name":"test_size","type":"\"long\""},{"metadata":"{}","name":"conversions","type":"\"long\""},{"metadata":"{}","name":"conversion_rate","type":"\"double\""},{"metadata":"{}","name":"sub_total","type":"\"double\""},{"metadata":"{}","name":"vouchers_used","type":"\"long\""},{"metadata":"{}","name":"aov","type":"\"double\""}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n","  .table-result-container {\n","    max-height: 300px;\n","    overflow: auto;\n","  }\n","  table, th, td {\n","    border: 1px solid black;\n","    border-collapse: collapse;\n","  }\n","  th, td {\n","    padding: 5px;\n","  }\n","  th {\n","    text-align: left;\n","  }\n","</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>test_assignment</th><th>test_size</th><th>conversions</th><th>conversion_rate</th><th>sub_total</th><th>vouchers_used</th><th>aov</th></tr></thead><tbody><tr><td>control</td><td>147962</td><td>10899</td><td>0.074</td><td>0.0</td><td>0</td><td>2330.0</td></tr><tr><td>test</td><td>164460</td><td>12093</td><td>0.074</td><td>339914.0</td><td>882</td><td>2298.0</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### 2. Important Metrics"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2ae42ef8-975f-4118-9cb5-8a44ccd245a5","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["**Incremental Response Rate**: Is the difference between the conversion rate observed in the group who received the treatment compared to the group who did not receive it. It represents the conversion rate that was actually incremental due to the treatment.\n\n$$IRR = \\\\text{Conversion}{_{treament}}-\\\\text{Conversion}{_{control}}$$ \n\n**Incremental Conversions (or incremental MUB)**: \n\n$$MUB_{i} = \\\\text{IRR} \\\\times \\\\text{N}_{treatment}$$ \n\n**Cannibalization**: estimates the proportion of conversions that would be made anyway, if we had not sent the incentive. \n\n$$Cannib_{treatment} = \\\\frac{\\\\text{Conversions with subsidy} - (\\\\text{IRR} \\\\times \\\\text{N}_{treatment}) } {\\\\text{\\\\text{Conversions with subsidy}}}{}$$\n\n**NIR(net incremental revenue):** how much revenue is made (or lost) by sending out the promotion. (Important to normalize by the number of customers in the treatment and control in case the sizes are different)\n\n$$NIR = \\\\text{Revenue}{_{treament}}-\\\\text{Revenue}{_{control}}$$  \n\n**Cost per Increment**: how much we are paying for each incremental conversion\n\n$$CPI = \\\\frac{\\\\text{Investment}_{treament}}{\\\\text{MUB}{_{i}}}$$"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"2f5c2622-4beb-484c-99fc-4a675568ce8a","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["Considering the metrics above, we could evaluate the overall results of our test as follows:\n\n- The incremental response rate (IRR) was 0%, because there was no difference in conversion between the test and the control;\n- The incremental MUB and the NIR is zero;\n- The Cannibalization rate is 100%, because we had no incremental conversions;\n- The Cost per Increment is N/A because the we had no incremental conversions;\n- **The campaign resulting P/L is NIR - total subsidy = 0 - 339,914 = MU$ - 339,914**\n\nAt first look we could say: this test flopped - we are not going to rollout this treatment, i.e., sending discount vouchers in order to foster growth;  \n\nHowever, this is where things get funnier: we could develop a targetting strategy in order to rollout this treatment only to groups of users who have, in fact, an **incremental behavior**."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1d174dd2-20e7-4b74-ab31-6d4c02305395","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["#### 3. A targetting example with a simple heuristic"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"72c299d5-5e87-4cff-afa5-4e63f5176129","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["After some analyses, the Data Analytics team recommended to target this treatment only to customers who had an average order value (AOV) of MU$ 2000 or more.  \nThis recommendation could trigger a post-hoc test or the rollout itself.  \nSimulating the results we'd have by segmenting our test by this heuristic, we'd have this:"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"b4162b7c-f10e-4bbd-ac89-691bce4ffe1c","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["target_customers =( \n  orders_sample\n  .filter(f.col('reference_date')>='2021-05-01')\n  .filter(f.col('reference_date')<'2021-06-01')\n  .groupBy('account_id')\n  .agg(\n      f.avg('order_total').alias('aov')\n  )\n  .filter(f.col('aov')<2000)\n  .select('account_id')\n  .distinct()\n)\n\n(\n    kairos_sample\n    .filter(f.col('reference_month')=='2021-06-01')\n    .join(target_customers, ['account_id'], 'inner')\n    .join(orders_by_account,  ['account_id', 'reference_date'], 'left')\n    .groupBy('test_assignment')\n    .agg(\n        f.count('account_id').alias('test_size'),\n        f.round((f.sum( f.when(f.col('orders') > 0, 1).otherwise(0) )), 3).alias('conversions'),\n        f.round((f.sum( f.when(f.col('orders') > 0, 1).otherwise(0) ) / f.count('account_id') ), 3).alias('conversion_rate'),\n        f.round(f.sum('subsidy'), 0).alias('sub_total'),\n        (f.sum( f.when(f.col('vouchers_used') > 0, 1).otherwise(0) ) ).alias('vouchers_used'),\n        f.avg('aov').alias('aov')\n    )    \n    .display()\n)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"nuid":"8c4f26d1-4667-4e04-82f8-3538ff9c2ad1","inputWidgets":{},"title":""}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"overflow":false,"datasetInfos":[],"data":[["control",19306,4779,0.248,0.0,0,1557.3070068703385],["test",21602,5563,0.258,194044.0,504,1533.9450220204956]],"plotOptions":{"displayType":"table","customPlotOptions":{},"pivotColumns":null,"pivotAggregation":null,"xColumns":null,"yColumns":null},"columnCustomDisplayInfos":{},"aggType":"","isJsonSchema":true,"removedWidgets":[],"aggSchema":[],"schema":[{"metadata":"{}","name":"test_assignment","type":"\"string\""},{"metadata":"{}","name":"test_size","type":"\"long\""},{"metadata":"{}","name":"conversions","type":"\"long\""},{"metadata":"{}","name":"conversion_rate","type":"\"double\""},{"metadata":"{}","name":"sub_total","type":"\"double\""},{"metadata":"{}","name":"vouchers_used","type":"\"long\""},{"metadata":"{}","name":"aov","type":"\"double\""}],"aggError":"","aggData":[],"addedWidgets":{},"metadata":{},"dbfsResultPath":null,"type":"table","aggOverflow":false,"aggSeriesLimitReached":false,"arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n","  .table-result-container {\n","    max-height: 300px;\n","    overflow: auto;\n","  }\n","  table, th, td {\n","    border: 1px solid black;\n","    border-collapse: collapse;\n","  }\n","  th, td {\n","    padding: 5px;\n","  }\n","  th {\n","    text-align: left;\n","  }\n","</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>test_assignment</th><th>test_size</th><th>conversions</th><th>conversion_rate</th><th>sub_total</th><th>vouchers_used</th><th>aov</th></tr></thead><tbody><tr><td>control</td><td>19306</td><td>4779</td><td>0.248</td><td>0.0</td><td>0</td><td>1557.3070068703385</td></tr><tr><td>test</td><td>21602</td><td>5563</td><td>0.258</td><td>194044.0</td><td>504</td><td>1533.9450220204956</td></tr></tbody></table></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["Now let's evaluate the results:  \n\n- The incremental response rate (IRR) was +1.0%;\n- The incremental MUB is 1.% * 21773 = 218 conversions\n- The NIR is ( (1534 * 0.258) - (1557 * 0.248) ) * 21773 =  $MU 209,804\n- The Cannibalization rate is (504 - 218)/ 504 = 56.6%. It means that around 57% of the vouchers used, were \"used by customers who did not need it to make a purchase\"\n- The Cost per Increment is roughly MU$ 194k / 218 = MU$ 890\n- The campaign incremental profit is NIR - total subsidy = 209,804 - 194,044 = MU$ 15,760\n\n**Is that good enough?**"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"c6ae582e-045e-41b9-b296-3c1d97a2aa7a","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["Sending the promotional campaign to everyone resulted in ZERO incremental conversions and a resulting loss of - MU$ 339 K. If we sent this promotional campaign only to users with an Average Order Values below MU $ in the previous month, we'd have an incremental response rate of 1%, at MU$890 for each incremental conversion, resulting in a profit of MU$15,760."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d37f9c35-ed23-465f-9902-d40d8e16a743","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["#### 4. Your Assignment\n\nYou need to develop a targetting strategy, using machine learning. You are going to create a model that will support the decision of whom should be targetted by this promotional campaign, in order to yield the best possible result.  \n\nThere are different ways to do this with unsupervised or supervised learning and you are free to use your creativity. I provide some hints at the end of the notebook, however.\n\nDespite of what way you choose to follow, these are the expected deliverables: \n\n- 1. When creating the dataframe that will be used to train your model, you need to create at least 3 features for each member in your team (at least 1 from items, 1 from orders and 1 from sessions datasets);\n  - Features documentation: describe the features you are creating and their semantic\n- 2. Train a Tune `PipelineModel` that executes the preprocessing and modelling steps\n  - Present an explanation of why you chose each step;\n  - Present an analysis of the experiment results of your hyperparameter tuning;\n- 3. Similar to what whas presented in the step 3 of this notebook, compare the expected results when your targetting is applied. Compare the results to the baseline results in step 3, using the metrics provided in step 2\n  - This result analysis should be done using **july test results** which are not yet available. 3 days before the deadline, you'll be able to download july test results and perform the final analysis before submitting the project."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f240645c-6bf8-4c6e-be1d-ee91848ce7e1","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["The final output should be a `.zip` file, containing (1) the `Blueprint Notebook` provided and (2) the `Pipeline Model artefacts`;"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"17fda7ec-aa18-433e-b6ce-f64079794c12","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["#### 5. Evaluation Criteria"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"9b0ab9a4-544c-4242-ba36-6f7cafd9c827","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":[">40% Data Manipulation\n- your code is well structured: your code is correctly indented, pyspark chaining methods are well organized and functions and variables have good naming, and use lowercase words separated by underscores;\n- your features are well documented and the code creating them matches the explanation presented;\n\n>30% ML Pipeline\n- You have trained a pipeline model and uploaded the artefacts;\n- You have presented a discussion of why you chose each step of your pipeline;\n- You have presented the tuning results of your model;\n\n>30% Targetting strategy\n- You have analyzed the results of the test using your targetting, similar to the step 2 of this notebook, on july test;\n- You have compared the results of your targetting to the baseline heuristic target = users with AOV > $MU 2000;\n- Your ranking compared to other solutions (in terms of IRR and CPI);"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"5020c983-07d6-4119-819e-094adfbf94b7","inputWidgets":{},"title":""}}},{"cell_type":"markdown","source":["#### 6. Some Hints\n\n- Here is a complete hands-on example of how to tackle this kind of problem: https://medium.com/@nesreensada/how-to-build-a-profitable-promotion-strategy-easily-with-uplift-modeling-26b2addc3e46\n\n- No idea where to start? Here you can find some inspiration on which model to use: https://medium.com/@nesreensada/how-to-build-a-profitable-promotion-strategy-easily-with-uplift-modeling-26b2addc3e46. **Remember:** you will not be evaluated by the quality of your model, the goal of this practical exam is to test you knowledge in understanding data and applying this knowledge in a data pipeline in Spark.\n\n- If you want a depper yet gentle introduction to uplift modelling, check this paper: https://proceedings.mlr.press/v67/gutierrez17a/gutierrez17a.pdf\n\n- The content above should help you decide how to model your `y` label and how to tackle the problem itself. In case you are still struggling after checking it out, we can provided further tips on the `Lab 14`\n."],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"4fab8e34-3c77-4fec-8324-3764b7b49619","inputWidgets":{},"title":""}}},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"cd0c34cc-f3f3-4756-9a80-4b587c073122","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"BDA Final Project","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{}}},"nbformat":4,"nbformat_minor":0}
